{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513516d5",
   "metadata": {},
   "source": [
    "# Web Ingestion Example\n",
    "\n",
    "This notebook demonstrates how to use the web ingestion utilities to process a website URL and store the chunks in a vector store for question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fa32389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from utils.model_costs import ModelUsageAsync\n",
    "from utils.openai_calls import call_openai_structured\n",
    "\n",
    "# Add web-specific imports\n",
    "from utils.web_ingestion import ingest_web_url, WebChunk, WebDocument\n",
    "from utils.vector_store import VectorStore, get_query_embedding\n",
    "\n",
    "load_dotenv() # .env should be in the root folder (sibling of this notebook)\n",
    "\n",
    "load_dotenv()  # .env should be in the root folder (sibling of this notebook)\n",
    "\n",
    "openai_client = AsyncOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_PROJECT_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "533ec594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed URL: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\n",
      "Extracted 51 chunks\n",
      "Processed URL: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\n",
      "Page title: US8812435B1 - Learning objects and facts from documents - Google Patents\n",
      "Created 51 chunks\n",
      "Embedding tokens used: 16095\n",
      "Embedding cost: $0.0003219\n",
      "\n",
      "Sample chunk:\n",
      "URL: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\n",
      "Characters: 0 to 1682\n",
      "Tokens: 327\n",
      "Text excerpt: This application is related to U.S. Utility patent application Ser. No. 11/394,610, entitled “Determining Document Subject by Using Title and Anchor Text of Related Documents,” by Shubin Zhao, filed o...\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"python\", \"-m\", \"playwright\", \"install\"])\n",
    "\n",
    "# URL to process (replace with any URL you want to analyze)\n",
    "url = \"https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\"\n",
    "\n",
    "# Create usage tracker\n",
    "web_ingestion_usage = ModelUsageAsync()\n",
    "\n",
    "# Process the web page: extract text, chunk, and embed\n",
    "web_doc, chunks = await ingest_web_url(\n",
    "    url=url,\n",
    "    openai_client=openai_client,\n",
    "    target_chunk_tokens=350,  # As specified in the tech spec\n",
    "    chunk_overlap=0.3,        # 30% overlap as specified\n",
    "    embedding_model=\"text-embedding-3-small\",\n",
    "    llm_usage=web_ingestion_usage\n",
    ")\n",
    "\n",
    "# Print some stats\n",
    "print(f\"Processed URL: {web_doc.url}\")\n",
    "print(f\"Page title: {web_doc.title}\")\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "print(f\"Embedding tokens used: {await web_ingestion_usage.get_tokens_used()}\")\n",
    "print(f\"Embedding cost: ${await web_ingestion_usage.get_cost()}\")\n",
    "\n",
    "# Display first chunk as example\n",
    "if chunks:\n",
    "    first_chunk = chunks[0]\n",
    "    print(\"\\nSample chunk:\")\n",
    "    print(f\"URL: {first_chunk.url}\")\n",
    "    if first_chunk.xpath:\n",
    "        print(f\"XPath: {first_chunk.xpath}\")\n",
    "    if first_chunk.css_selector:\n",
    "        print(f\"CSS Selector: {first_chunk.css_selector}\")\n",
    "    print(f\"Characters: {first_chunk.char_start} to {first_chunk.char_end}\")\n",
    "    print(f\"Tokens: {first_chunk.tokens}\")\n",
    "    print(f\"Text excerpt: {first_chunk.text[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb2d2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 51 chunks to vector store\n"
     ]
    }
   ],
   "source": [
    "# Create vector store and add chunks\n",
    "vector_store = VectorStore(embedding_dim=1536)  # dimension for text-embedding-3-small\n",
    "vector_store.add_chunks(chunks)\n",
    "\n",
    "print(f\"Added {len(chunks)} chunks to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78876f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: A method to develop a search engine rank for object-source pairs within a corpus of published documents, the method comprising: semantically identifying, by an evaluation module, objects and source values contained within the corpus of published documents, wherein each source value is a name of an organization, and wherein the objects and source values each include one or more words identified within a published document in the corpus of published documents tying, by the evaluation module, each instance of a first object throughout the corpus of published documents to a source value based on: identifying a first instance of the first object in a first published document of the corpus of published documents\n",
      "Retrieved 6 relevant chunks\n",
      "\n",
      "Chunk 1:\n",
      "., the Encyclopedia Britannica Online) when selecting \n",
      "\n",
      " the source document.\n",
      "\n",
      "Alternatively, the \n",
      "\n",
      "...\n",
      "\n",
      "Chunk 2:\n",
      "ribute-value pairs identified by applying the general contextual pattern may be over-inclusive. If t...\n",
      "\n",
      "Chunk 3:\n",
      "f a given type by sharing a common object ID at least with a type fact indicating the given type (or...\n",
      "\n",
      "Chunk 4:\n",
      "on rules, an object name of “Charles Chaplin” becomes “charles chaplin”.\n",
      "\n",
      "In one embodiment, the imp...\n",
      "\n",
      "Chunk 5:\n",
      "hor Text of Related Documents,” filed on Mar. 31, 2006, the disclosure of which is hereby incorporat...\n",
      "\n",
      "Chunk 6:\n",
      "based on the subject of the source document. For example, the \n",
      "\n",
      " can first identify a title pattern ...\n",
      "\n",
      "Embedding tokens used: 124\n",
      "Embedding cost: $2.48e-06\n"
     ]
    }
   ],
   "source": [
    "# Define some test questions\n",
    "test_questions = [\n",
    "    \"A method to develop a search engine rank for object-source pairs within a corpus of published documents, the method comprising: semantically identifying, by an evaluation module, objects and source values contained within the corpus of published documents, wherein each source value is a name of an organization, and wherein the objects and source values each include one or more words identified within a published document in the corpus of published documents tying, by the evaluation module, each instance of a first object throughout the corpus of published documents to a source value based on: identifying a first instance of the first object in a first published document of the corpus of published documents\"\n",
    "]\n",
    "\n",
    "# Function to retrieve and display results\n",
    "async def query_document(question):\n",
    "    print(f\"\\nQuery: {question}\")\n",
    "    \n",
    "    # Track usage\n",
    "    query_usage = ModelUsageAsync()\n",
    "    \n",
    "    # Get embedding for query\n",
    "    query_embedding = await get_query_embedding(\n",
    "        query=question,\n",
    "        openai_client=openai_client,\n",
    "        embedding_model=\"text-embedding-3-small\",\n",
    "        llm_usage=query_usage\n",
    "    )\n",
    "    \n",
    "    # Retrieve relevant chunks with MMR for diversity\n",
    "    retrieved_chunks = vector_store.mmr_search(\n",
    "        query_embedding=query_embedding,\n",
    "        k=6,  # As specified in tech spec\n",
    "        lambda_param=0.7  # Balance between relevance and diversity\n",
    "    )\n",
    "    \n",
    "    print(f\"Retrieved {len(retrieved_chunks)} relevant chunks\")\n",
    "    \n",
    "    # Display retrieved chunks\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        print(f\"\\nChunk {i+1}:\")\n",
    "        # Display a preview of the text (first 100 characters)\n",
    "        print(f\"{chunk.text[:100]}...\")\n",
    "    \n",
    "    print(f\"\\nEmbedding tokens used: {await query_usage.get_tokens_used()}\")\n",
    "    print(f\"Embedding cost: ${await query_usage.get_cost()}\")\n",
    "    \n",
    "    return retrieved_chunks\n",
    "\n",
    "# Test with the first question\n",
    "retrieved_chunks = await query_document(test_questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b4e565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating answer for: A method to develop a search engine rank for object-source pairs within a corpus of published documents, the method comprising: semantically identifying, by an evaluation module, objects and source values contained within the corpus of published documents, wherein each source value is a name of an organization, and wherein the objects and source values each include one or more words identified within a published document in the corpus of published documents tying, by the evaluation module, each instance of a first object throughout the corpus of published documents to a source value based on: identifying a first instance of the first object in a first published document of the corpus of published documents\n",
      "\n",
      "Answer:\n",
      "The method uses an evaluation module to:\n",
      "\n",
      "1. Semantically identify candidate source documents by keyword‐searching for each object name together with its attribute‐value pairs:  \n",
      "   “Alternatively, the <…> searches for documents containing an object name of the source object and one or more of its facts (or attribute‐value pairs) in the plurality of documents.”  \n",
      "   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\n",
      "\n",
      "2. Select the canonical source by checking the document title for the object name (and, if absent, repeating with another document):  \n",
      "   “In one embodiment, the <…> determines whether the document title contains the source object name as a substring. A substring is a contiguous sequence of characters taken from a string. If the document title does not contain the source object name as a substring, the <…> repeats the above process and selects another document as the source document.”  \n",
      "   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\n",
      "\n",
      "3. Determine a title pattern to anchor the first instance and thus fix the source object identity:  \n",
      "   “The <…> can first identify a title pattern of the selected source document, determine an object name based on the document title and the title pattern, and select a source object associated with the object name.”  \n",
      "   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\n",
      "\n",
      "4. Tie every subsequent occurrence of that object in the corpus back to the chosen source by extracting and linking its attribute‐value pairs:  \n",
      "   “For each document in the selected set, the <…> the attribute‐value pairs identified in the document with an object with the identified name.”  \n",
      "   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\n",
      "\n",
      "Tokens used: 7750\n",
      "Answer cost: $0.0268598\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt for question answering with citations\n",
    "QA_WITH_CITATIONS_PROMPT = \"\"\"\n",
    "Task: Answer the user's question based ONLY on the provided context. \n",
    "Include verbatim quotes from the context to support your answer.\n",
    "Format your answer with cited text in quotes and include the URL source for each citation.\n",
    "\n",
    "User question: {user_question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Your answer must:\n",
    "1. Only contain information present in the context\n",
    "2. Include at least 2 direct quotes from the context\n",
    "3. Specify the URL source for each quote\n",
    "4. Be concise and focused on the question\n",
    "\"\"\"\n",
    "\n",
    "async def answer_with_citations(question, retrieved_chunks):\n",
    "    print(f\"\\nGenerating answer for: {question}\")\n",
    "    \n",
    "    # Format context from chunks\n",
    "    context_parts = []\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        context_parts.append(f\"Source {i+1} - {chunk.url}:\\n{chunk.text}\\n\")\n",
    "    \n",
    "    context = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # Create message history\n",
    "    message_history = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert assistant that answers questions based solely on provided context.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": QA_WITH_CITATIONS_PROMPT.format(\n",
    "                user_question=question,\n",
    "                context=context\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Track usage\n",
    "    answer_usage = ModelUsageAsync()\n",
    "    \n",
    "    # Call LLM to generate answer\n",
    "    model_response = await call_openai_structured(\n",
    "        openai_client=openai_client,\n",
    "        model=\"o4-mini\",  # First call with o4-mini as specified\n",
    "        messages=message_history,\n",
    "        reasoning_effort=\"high\",\n",
    "        llm_usage=answer_usage\n",
    "    )\n",
    "    \n",
    "    answer = model_response.choices[0].message.content\n",
    "    \n",
    "    print(f\"\\nAnswer:\\n{answer}\")\n",
    "    print(f\"\\nTokens used: {await answer_usage.get_tokens_used()}\")\n",
    "    print(f\"Answer cost: ${await answer_usage.get_cost()}\")\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Generate answer for the first question\n",
    "answer = await answer_with_citations(test_questions[0], retrieved_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc2ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Formatting answer as JSON...\n",
      "\n",
      "JSON Output:\n",
      "```json\n",
      "{\n",
      "  \"answer\": \"The method uses an evaluation module to:\\n\\n1. Semantically identify candidate source documents by keyword‐searching for each object name together with its attribute‐value pairs:\\n   “Alternatively, the <…> searches for documents containing an object name of the source object and one or more of its facts (or attribute‐value pairs) in the plurality of documents.”\\n   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\\n\\n2. Select the canonical source by checking the document title for the object name (and, if absent, repeating with another document):\\n   “In one embodiment, the <…> determines whether the document title contains the source object name as a substring. A substring is a contiguous sequence of characters taken from a string. If the document title does not contain the source object name as a substring, the <…> repeats the above process and selects another document as the source document.”\\n   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\\n\\n3. Determine a title pattern to anchor the first instance and thus fix the source object identity:\\n   “The <…> can first identify a title pattern of the selected source document, determine an object name based on the document title and the title pattern, and select a source object associated with the object name.”\\n   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\\n\\n4. Tie every subsequent occurrence of that object in the corpus back to the chosen source by extracting and linking its attribute‐value pairs:\\n   “For each document in the selected set, the <…> the attribute‐value pairs identified in the document with an object with the identified name.”\\n   Source: https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\",\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"url\": \"https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\",\n",
      "      \"text\": \"Alternatively, the <…> searches for documents containing an object name of the source object and one or more of its facts (or attribute-value pairs) in the plurality of documents.\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\",\n",
      "      \"text\": \"In one embodiment, the <…> determines whether the document title contains the source object name as a substring. A substring is a contiguous sequence of characters taken from a string. If the document title does not contain the source object name as a substring, the <…> repeats the above process and selects another document as the source document.\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\",\n",
      "      \"text\": \"The <…> can first identify a title pattern of the selected source document, determine an object name based on the document title and the title pattern, and select a source object associated with the object name.\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://patents.google.com/patent/US8812435B1/en?oq=US8812435B1\",\n",
      "      \"text\": \"For each document in the selected set, the <…> the attribute-value pairs identified in the document with an object with the identified name.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Tokens used: 3919\n",
      "JSON formatting cost: $0.0156068\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt for structured JSON output\n",
    "JSON_FORMATTER_PROMPT = \"\"\"\n",
    "Format the following answer into a valid JSON structure with these fields:\n",
    "1. \"answer\": The complete answer text\n",
    "2. \"citations\": An array of citation objects, each with \"url\" and \"text\" fields\n",
    "\n",
    "Original answer:\n",
    "{answer}\n",
    "\n",
    "Return ONLY the JSON object, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "async def format_as_json(answer):\n",
    "    print(\"\\nFormatting answer as JSON...\")\n",
    "    \n",
    "    # Create message history\n",
    "    message_history = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that formats text as valid JSON.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": JSON_FORMATTER_PROMPT.format(answer=answer)\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Track usage\n",
    "    json_usage = ModelUsageAsync()\n",
    "    \n",
    "    # Call LLM to format as JSON\n",
    "    model_response = await call_openai_structured(\n",
    "        openai_client=openai_client,\n",
    "        model=\"o4-mini\",  # Using o4-mini for the formatting pass\n",
    "        messages=message_history,\n",
    "        reasoning_effort=\"medium\",\n",
    "        llm_usage=json_usage\n",
    "    )\n",
    "    \n",
    "    json_response = model_response.choices[0].message.content\n",
    "    \n",
    "    print(f\"\\nJSON Output:\\n{json_response}\")\n",
    "    print(f\"\\nTokens used: {await json_usage.get_tokens_used()}\")\n",
    "    print(f\"JSON formatting cost: ${await json_usage.get_cost()}\")\n",
    "    \n",
    "    return json_response\n",
    "\n",
    "# Format the answer as JSON\n",
    "json_output = await format_as_json(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41a2fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What are the major applications of NLP?\n",
      "Retrieved 6 relevant chunks\n",
      "\n",
      "Chunk 1:\n",
      "neural networks approach, using semantic networks[23] and word embeddings to capture semantic proper...\n",
      "\n",
      "Chunk 2:\n",
      "Field of linguistics and computer science\n",
      "\n",
      "Natural language processing (NLP) is a subfield of comput...\n",
      "\n",
      "Chunk 3:\n",
      "h techniques[11][12] can achieve state-of-the-art results in many natural language tasks, e.g., in l...\n",
      "\n",
      "Chunk 4:\n",
      "tive AI\".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (althoug...\n",
      "\n",
      "Chunk 5:\n",
      "t the time.[4]\n",
      "\n",
      "1970s: During the 1970s, many programmers began to write \"conceptual ontologies\", wh...\n",
      "\n",
      "Chunk 6:\n",
      "processing with the introduction of machine learning algorithms for language processing.  This was d...\n",
      "\n",
      "Embedding tokens used: 9\n",
      "Embedding cost: $1.8e-07\n",
      "\n",
      "Generating answer for: What are the major applications of NLP?\n",
      "\n",
      "Answer:\n",
      "Here are some of the major real-world applications of NLP, drawn directly from the provided context:\n",
      "\n",
      "1.   “Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.”  \n",
      "     Source: https://en.wikipedia.org/wiki/Natural_language_processing\n",
      "\n",
      "2.   “Neural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.”  \n",
      "     Source: https://en.wikipedia.org/wiki/Natural_language_processing\n",
      "\n",
      "3.   “This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care or protect patient privacy.”  \n",
      "     Source: https://en.wikipedia.org/wiki/Natural_language_processing\n",
      "\n",
      "Tokens used: 3001\n",
      "Answer cost: $0.0071059999999999995\n",
      "\n",
      "Formatting answer as JSON...\n",
      "\n",
      "JSON Output:\n",
      "{\"answer\":\"Here are some of the major real-world applications of NLP, drawn directly from the provided context:\\n\\n1. “Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.”\\n2. “Neural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.”\\n3. “This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care or protect patient privacy.”\",\"citations\":[{\"url\":\"https://en.wikipedia.org/wiki/Natural_language_processing\",\"text\":\"Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.\"},{\"url\":\"https://en.wikipedia.org/wiki/Natural_language_processing\",\"text\":\"Neural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\"},{\"url\":\"https://en.wikipedia.org/wiki/Natural_language_processing\",\"text\":\"This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care or protect patient privacy.\"}]}\n",
      "\n",
      "Tokens used: 1637\n",
      "JSON formatting cost: $0.0063745\n"
     ]
    }
   ],
   "source": [
    "# Try another question\n",
    "if len(test_questions) > 1:\n",
    "    retrieved_chunks = await query_document(test_questions[1])\n",
    "    answer = await answer_with_citations(test_questions[1], retrieved_chunks)\n",
    "    json_output = await format_as_json(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
